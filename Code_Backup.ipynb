{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "###There is something you need to change before using\n",
    "# change the path where jupyter access\n",
    "Path=r'C:\\Users\\Simu\\Desktop\\BRISTOL\\DSMP'\n",
    "#where change the path of data in \"additional folder\"\n",
    "path_add_folder=r'C:\\Users\\Simu\\Desktop\\BRISTOL\\DSMP\\925 Data additional data'\n",
    "#where change the path of data in \"Rise data\"\n",
    "path_rise_folder=r'C:\\Users\\Simu\\Desktop\\BRISTOL\\DSMP\\Ceara Rise data'\n",
    "sys.path.append(Path)\n",
    "#merge name of excel into list files\n",
    "files_add = [file for file in os.listdir(path_add_folder) \n",
    "             if file.endswith('.csv') or file.endswith('.xlsx')]\n",
    "files_rise = [file for file in os.listdir(path_rise_folder) \n",
    "             if file.endswith('.csv') or file.endswith('.xlsx')]\n",
    "def read_all_excel_from_folder(path,files):\n",
    "    #initialize a library to storage\n",
    "    list=[]\n",
    "    for file in files:\n",
    "        #join the path of excel to the path of folder\n",
    "        file_path = os.path.join(path,file)\n",
    "        #get data with panda\n",
    "        if file.endswith('.csv'):\n",
    "            df = pd.read_csv(file_path)\n",
    "        else:\n",
    "            df = pd.read_excel(file_path)\n",
    "        #get name of excel without exthension\n",
    "        file_name_without_extension = os.path.splitext(file)[0]\n",
    "        #storage data in library with name of excel to index\n",
    "        list.append(df)\n",
    "    return list\n",
    "\n",
    "##storage data from additon_folder\n",
    "excels_add= read_all_excel_from_folder(path_add_folder,files_add)\n",
    "#example of indexing\n",
    "print(excels_add[0])\n",
    "#because the name of excel is complex so we read the name of file with number\n",
    "#but it is ok to index with(excel_add[files_add.index('name')])\n",
    "print(excels_add[files_add.index(files_add[0])])\n",
    "\n",
    "##storage fata from rise_folder\n",
    "excels_rise= read_all_excel_from_folder(path_rise_folder,files_rise)\n",
    "print(excels_rise[0])\n",
    "\n",
    "pip install openpyxl\n",
    "    ***I will change name of columns to make sure every excel have same columns , take out blank columns identified by panda and take out last three lines in excel of file\"rise\" because they are not data about specific samples(you can see why in details by opening excels in 'rise' file)\n",
    "    add columns in excel which miss \"area\" and \"Perimeter (Âµm)\"\n",
    "    rearrange columns by letters\n",
    "    rename colimns\n",
    "    add columns for indexing age\n",
    "import re\n",
    "#get value of attributes from filenames\n",
    "def pre_filenames(filenames):\n",
    "    name_attribute = []\n",
    "    for filename in filenames:\n",
    "        # take out extension and \"measure ....\"\n",
    "        filename = os.path.splitext(filename)[0]\n",
    "        filename = filename.replace(\"Count and Measure of\", \"\").strip()\n",
    "        # get elements of number and letter\n",
    "        elements = re.findall(r'\\d+\\.\\d+|\\d+|[a-zA-Z]', filename)\n",
    "        # take out \"-\"\n",
    "        parsed_elements=[]\n",
    "        for element in elements:\n",
    "            parsed_elements.extend(re.split(r'[-]', element))\n",
    "            \n",
    "        while len(parsed_elements) < 7:\n",
    "            parsed_elements.append(None)  # Fill with `None` if missing\n",
    "\n",
    "        name_attribute.append(parsed_elements)\n",
    "    return name_attribute\n",
    "# function to reneme columns\n",
    "def rename_columns(excels):\n",
    "    new_columns = ['Area (ÂµmÂ²)', \n",
    "                   'Elongation', \n",
    "                   'Max (Diameter) (Âµm)',\n",
    "                   'Mean (Diameter) (Âµm)', \n",
    "                   'Mean (Gray Intensity Value)',\n",
    "                   'Min (Diameter) (Âµm)', \n",
    "                   'Object ID', \n",
    "                   'Perimeter (Âµm)', \n",
    "                   'Shape Factor',\n",
    "                   'Sphericity']\n",
    "    excels = [excel.rename(columns=dict(zip(excel.columns,new_columns))) for excel in excels]\n",
    "    return excels\n",
    "def add_columns(excels,name_lists):\n",
    "    excels=[excel.assign(\n",
    "        SITE = name[0],\n",
    "        HOLE = name[1],\n",
    "        CORE = name[2],\n",
    "        CORE_TYPE=name[3],\n",
    "        SECTION=name[4],\n",
    "        TOP_DEPTH=name[5],\n",
    "        BOTTOM_DEPTH=name[6]\n",
    "        ) for excel,name in zip(excels,name_lists)]\n",
    "    return excels\n",
    "\n",
    "def drop_columns(excels,columns_name):\n",
    "    return [df.drop(columns=[columns_name], errors='ignore') for df in excels]\n",
    "\n",
    "#get name of files\n",
    "pre_filenames_add=pre_filenames(files_add)\n",
    "#print(pre_filenames_add)\n",
    "pre_filenames_rise=pre_filenames(files_rise)\n",
    "\n",
    "\n",
    "for i in range(len(excels_rise)):\n",
    "    if excels_rise[i].shape[1]<excels_rise[0].shape[1]:\n",
    "        excels_rise[i][\"Area (ÂµmÂ²)\"]=pd.NA\n",
    "        excels_rise[i][\"Perimeter (Âµm)\"]=pd.NA\n",
    "#test whether they have same number of columns\n",
    "for i in range(len(excels_rise)):\n",
    "    if excels_rise[i].shape[1]<excels_rise[0].shape[1]:\n",
    "        print(excels_rise[i].columns)\n",
    "        print(excels_rise[0].columns)\n",
    "        print(i)\n",
    "        \n",
    "#drop unuseful column in \"additional\" excel\n",
    "excels_add_name= drop_columns(excels_add, 'Unnamed: 0')\n",
    "#drop unuseful column in  \"rise\" excel\n",
    "excels_rise_name= drop_columns(excels_rise, 'Statistics')\n",
    "\n",
    "#rearrange columns by letters\n",
    "excels_add_name_re= [excel[sorted(excel.columns)] for excel in excels_add_name ]\n",
    "excels_rise_name_re = [excel[sorted(excel.columns)] for excel in excels_rise_name]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#rename columns\n",
    "excels_add_columns_rename= rename_columns(excels_add_name_re)\n",
    "\n",
    "excels_rise_columns_rename= rename_columns(excels_rise_name_re)\n",
    "excels_rise_columns_rename= [excel.iloc[:-3] for excel in excels_rise_columns_rename]\n",
    "\n",
    "#add columns which is used to index age\n",
    "pre_filenames_rise[253][-1]=84.5\n",
    "pre_filenames_rise[253].append(\"86.5\")\n",
    "excels_add_columns_index= add_columns(excels_add_columns_rename,pre_filenames_add)\n",
    "excels_rise_columns_index= add_columns(excels_rise_columns_rename,pre_filenames_rise)\n",
    "print(excels_rise_columns_index[3])\n",
    "excels_add_final = excels_add_columns_index\n",
    "excels_rise_final = excels_rise_columns_index\n",
    "print(excels_add_final[3].columns)\n",
    "print(excels_rise_final[3].columns)\n",
    "print(len(excels_add_final))\n",
    "print(len(excels_rise_final))\n",
    "for i in range(len(excels_add_final)):\n",
    "    excels_add_final[i]['ID']=i\n",
    "print(excels_add_final[1])\n",
    "for j in range(len(excels_rise_final)):\n",
    "    excels_rise_final[j]['ID']=j+len(excels_add_final)\n",
    "print(excels_rise_final[-1]['ID'])\n",
    "    ***Merge excels in excels in 'rise' file and 'additional' file.\n",
    "    Alse try to merge samples excels with 'Mastersheet'file to see whether it can add 'age' columns to samples excels.\n",
    "Master_sheet_stay=pd.read_excel(r\"C:\\Users\\Simu\\Desktop\\BRISTOL\\DSMP\\925_Mastersheet (1).xlsx\",engine='openpyxl', header=1)  # Adjust header row\n",
    "# Strip spaces and newlines from column names\n",
    "Master_sheet_stay.columns = Master_sheet_stay.columns.str.strip().str.replace(\"\\n\", \"_\", regex=True)\n",
    "\n",
    "print(Master_sheet_stay.columns)  # Check if columns are correct\n",
    "\n",
    "\n",
    "Master_sheet =Master_sheet_stay.iloc[:-3]\n",
    "# make suer type is same\n",
    "def standardize_types(df):\n",
    "    # Convert only numeric values, replacing non-numeric with NaN\n",
    "    df[\"CORE\"] = pd.to_numeric(df[\"CORE\"], errors='coerce')  # Convert, replacing errors with NaN\n",
    "    df[\"SITE\"] = pd.to_numeric(df[\"SITE\"], errors='coerce')\n",
    "    df[\"HOLE\"] = df[\"HOLE\"].astype(str)  # Keep as string\n",
    "    df[\"CORE_TYPE\"] = df[\"CORE_TYPE\"].astype(str)\n",
    "    df[\"SECTION\"] = pd.to_numeric(df[\"SECTION\"], errors='coerce')\n",
    "    df[\"TOP_DEPTH\"] = pd.to_numeric(df[\"TOP_DEPTH\"], errors='coerce')\n",
    "    df[\"BOTTOM_DEPTH\"] = pd.to_numeric(df[\"BOTTOM_DEPTH\"], errors='coerce')\n",
    "    return df\n",
    "print(Master_sheet.dtypes)\n",
    "print(excels_rise_final[3].dtypes)\n",
    "print(excels_add_final[2].dtypes)\n",
    "Master_sheet = standardize_types(Master_sheet)\n",
    "excels_rise_final_st = [standardize_types(df) for df in excels_rise_final]\n",
    "excels_add_final_st = [standardize_types(df) for df in excels_add_final]\n",
    "# drop lines where age is empty\n",
    "key_columns = [\"SITE\", \"HOLE\", \"CORE\", \"CORE_TYPE\", \"SECTION\", \"TOP_DEPTH\", \"BOTTOM_DEPTH\", \"Age (Ma)\"]\n",
    "key_index=[\"SITE\", \"HOLE\", \"CORE\", \"CORE_TYPE\", \"SECTION\", \"TOP_DEPTH\", \"BOTTOM_DEPTH\"]\n",
    "mastersheet_filtered = Master_sheet[key_columns].dropna(subset=[\"Age (Ma)\"])\n",
    "excels_rise_final_std = [excel_rise_final_st.dropna(subset=key_index) for excel_rise_final_st in excels_rise_final_st ]\n",
    "excels_add_final_std = [excel_add_final_st.dropna(subset=key_index) for excel_add_final_st in excels_add_final_st] \n",
    "print(excels_rise_final_st[3])\n",
    "\n",
    "# merge function which wil be used by map\n",
    "def add_age_info(df):\n",
    "    df = df.copy()  \n",
    "    for col in [\"HOLE\", \"CORE_TYPE\"]:\n",
    "        df[col] = df[col].astype(str)\n",
    "    merged_df = df.merge(mastersheet_filtered, \n",
    "                         on=[\"SITE\", \"HOLE\", \"CORE\", \"CORE_TYPE\", \"SECTION\", \"TOP_DEPTH\", \"BOTTOM_DEPTH\"], \n",
    "                         how=\"left\")\n",
    "    return merged_df\n",
    "\n",
    "# storage with age\n",
    "excels_add_final_updated = [add_age_info(df) for df in excels_add_final_st ]\n",
    "print(excels_add_final_updated[-1]['ID'])\n",
    "excels_rise_final_updated = [add_age_info(df) for df in excels_rise_final_st]\n",
    "print(excels_rise_final_updated[-1]['ID'])\n",
    "print(excels_rise_final_updated[0]['ID'])\n",
    "#merge excels of samples\n",
    "excel_add_whole = pd.concat(excels_add_final_updated,ignore_index=True,axis=0)\n",
    "print(excel_add_whole['ID'].nunique())\n",
    "excel_rise_whole =pd.concat(excels_rise_final_updated,ignore_index=True,axis=0)\n",
    "print(excel_rise_whole['ID'].nunique())\n",
    "samples=pd.concat([excel_add_whole,excel_rise_whole],ignore_index=True,axis=0)\n",
    "print(samples['ID'].nunique())\n",
    "samples.to_csv(\"samples.csv\", index=False)\n",
    "samples[\"key\"] = samples[[\"SITE\", \"HOLE\", \"CORE\", \"CORE_TYPE\", \"SECTION\", \"TOP_DEPTH\", \"BOTTOM_DEPTH\"]].astype(str).agg(\"_\".join, axis=1)\n",
    "#set columns which used to group\n",
    "group_cols = [\"SITE\", \"HOLE\", \"CORE\", \"CORE_TYPE\", \"SECTION\", \"TOP_DEPTH\", \"BOTTOM_DEPTH\"]\n",
    "question_one_data = samples.groupby(group_cols).agg({\n",
    "    \"Max (Diameter) (Âµm)\": lambda x: x.quantile(0.95),\n",
    "    \"Elongation\": lambda x: x.quantile(0.95),\n",
    "    \"Age (Ma)\": \"first\",  \n",
    "    \"Min (Diameter) (Âµm)\": lambda x: x.quantile(0.05),\n",
    "    \"Shape Factor\": \"mean\",\n",
    "    \"Sphericity\":\"mean\"\n",
    "    \n",
    "}).reset_index()\n",
    "question_one_data = question_one_data.copy().dropna(subset=[\"Age (Ma)\",'Max (Diameter) (Âµm)','Elongation', \"Sphericity\", \"Shape Factor\",\"Min (Diameter) (Âµm)\"])\n",
    "print(question_one_data)\n",
    "question_one_data.to_csv(\"question_one_data.csv\", index=False)\n",
    "### Trying modified code by Cai on 15th Feb\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"C:/Users/Simu/Documents/Github/Data-Science-Mini-Project/question_one_data.csv\"\n",
    "save_path = \"C:/Users/Simu/Documents/Github/Data-Science-Mini-Project/plots/\"\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "df = pd.read_csv(file_path) #, sheet_name='Sheet1')\n",
    "\n",
    "\n",
    "print(\"\\nShape of data:\", df.shape)\n",
    "print(\"\\nMissing Values:\\n\", df.isnull().sum())\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "print(\"\\nSummary Statistics:\\n\", df.describe())\n",
    "\n",
    "df.rename(columns={\n",
    "    \"Age (Ma)\": \"Age_Ma\",\n",
    "    \"Max (Diameter) (Âµm)\": \"Max_Diameter\",\n",
    "    \"Min (Diameter) (Âµm)\": \"Min_Diameter\",\n",
    "    \"Elongation\": \"Elongation\"\n",
    "}, inplace=True)\n",
    "\n",
    "df_sorted = df.sort_values(by=\"Age_Ma\", ascending=True).reset_index(drop=True)\n",
    "\n",
    "# divid the data into two groups\n",
    "df_sorted[\"Age_Group\"] = pd.qcut(df_sorted[\"Age_Ma\"], q=5, labels=[\n",
    "    \"0.01-0.62MA\", \"0.63-1.31MA\", \"1.31-1.93MA\", \"1.93-2.76MA\", \"2.77-5.00MA\"\n",
    "])\n",
    "\n",
    "# calculate the gap of data\n",
    "age_label = df_sorted.groupby(\"Age_Group\")[\"Age_Ma\"].agg([\"min\", \"max\"])\n",
    "age_label[\"Interval\"] = age_label[\"max\"] - age_label[\"min\"]\n",
    "print(\"\\nLabeled Age Group Time Intervals (Million Years, Ma):\")\n",
    "print(age_label)\n",
    "\n",
    "\n",
    "selected_cols = [\"Max_Diameter\", \"Min_Diameter\", \"Elongation\"]\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "for col in selected_cols:\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.histplot(df_sorted[col], kde=True, bins=30)\n",
    "    plt.title(f\"Histogram of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.savefig(f\"{save_path}Histogram_{col}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "# outliers\n",
    "def detect_outliers_iqr(df, cols, factor=1.5):\n",
    "    outliers_info = {}\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        outlier_mask = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "        outliers_info[col] = {\n",
    "            \"lower_bound\": lower_bound,\n",
    "            \"upper_bound\": upper_bound,\n",
    "            \"count\": outlier_mask.sum(),\n",
    "            \"outliers\": df.loc[outlier_mask]\n",
    "        }\n",
    "    return outliers_info\n",
    "\n",
    "iqr_outliers = detect_outliers_iqr(df_sorted, selected_cols)\n",
    "for col, info in iqr_outliers.items():\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(f\"Lower bound: {info['lower_bound']:.2f}, Upper bound: {info['upper_bound']:.2f}\")\n",
    "    print(f\"Number of outliers: {info['count']}\")\n",
    "    print(f\"Example outliers:\\n{info['outliers'].head()}\")\n",
    "    \n",
    "def remove_outliers_iqr(df, cols, factor=1.5):\n",
    "    df_clean = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        df_clean = df_clean[(df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)]\n",
    "    return df_clean\n",
    "\n",
    "cleaned_data = remove_outliers_iqr(df_sorted, selected_cols)\n",
    "for feature in selected_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(data=cleaned_data , x=\"Age_Group\", y=feature, \n",
    "                order=[\"0.01-0.62MA\", \"0.63-1.31MA\", \"1.31-1.93MA\", \"1.93-2.76MA\", \"2.77-5.00MA\"])\n",
    "    plt.title(f\"Box Plot: {feature} Across Age Groups\")\n",
    "    plt.xlabel(\"Age Group\")\n",
    "    plt.ylabel(feature)\n",
    "    plt.savefig(f\"{save_path}BoxPlot_{feature}.png\", dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "for age_group in cleaned_data[\"Age_Group\"].unique():\n",
    "    df_group = cleaned_data[cleaned_data[\"Age_Group\"] == age_group]\n",
    "\n",
    "    for feature in selected_cols:\n",
    "        # ðŸ”¹ æ•£ç‚¹å›¾\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.scatterplot(data=df_group, x=\"Age_Ma\", y=feature, alpha=0.6, s=80)\n",
    "        plt.title(f\"Scatter Plot: {feature} in {age_group} (No Outliers)\")\n",
    "        plt.xlabel(\"Age (Ma)\")\n",
    "        plt.ylabel(feature)\n",
    "        plt.gca().invert_xaxis()  \n",
    "        plt.savefig(f\"{save_path}Scatter_{age_group}_{feature}_NoOutliers.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "        # ðŸ”¹ æŠ˜çº¿å›¾\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.lineplot(data=df_group, x=\"Age_Ma\", y=feature, marker=\"o\")\n",
    "        plt.title(f\"Line Plot: {feature} in {age_group} (No Outliers)\")\n",
    "        plt.xlabel(\"Age (Ma)\")\n",
    "        plt.ylabel(feature)\n",
    "        plt.gca().invert_xaxis()  \n",
    "        plt.savefig(f\"{save_path}Line_{age_group}_{feature}_NoOutliers.png\", dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "df_sorted[selected_cols + [\"Age_Ma\"]] = df_sorted[selected_cols + [\"Age_Ma\"]].apply(pd.to_numeric, errors='coerce')\n",
    "correlation_matrix = df_sorted[selected_cols + [\"Age_Ma\"]].corr()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"RdYlBu\", linewidths=0.5)\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.savefig(f\"{save_path}Correlation_Heatmap.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
